{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.random as ndm\n",
    "import torch\n",
    "from torch import nn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from data_generator import generate_case_3\n",
    "from iteration_deep import Est_deep\n",
    "from I_spline import I_S\n",
    "from Least_FD import LFD\n",
    "from iteration_linear import Est_linear\n",
    "from iteration_additive import Est_additive\n",
    "from sklearn.model_selection import train_test_split\n",
    "import dfply"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    np.random.seed(seed) \n",
    "    torch.manual_seed(seed) \n",
    "\n",
    "set_seed(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "initial values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tau = 10\n",
    "p = 3 \n",
    "Set_n = np.array([500, 1000, 2000])\n",
    "corr = 0.5 \n",
    "n_layer = 3\n",
    "n_node = 50\n",
    "n_epoch = 200 #\n",
    "Set_lr = np.array([2.8e-4, 3.2e-4, 4.2e-4]) #learning rate\n",
    "Beta = np.array([-0.5,1]) #regression parameter\n",
    "zeta = 2 #change point\n",
    "node_D = np.array([35, 30, 30])   #deep\n",
    "lr_D = np.array([4e-4, 4e-4, 4e-4])\n",
    "\n",
    "node_L = np.array([45, 45, 50])   #linear\n",
    "lr_L = np.array([1e-3, 1e-3, 1e-3])\n",
    "\n",
    "node_A = np.array([30, 30, 30])   #addictive\n",
    "lr_A = np.array([3e-4, 3e-4, 3e-4])\n",
    "\n",
    "B = 200  #repulications "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "generate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Z': array([1., 1., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1., 1., 1., 0., 0.,\n",
      "       1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1.,\n",
      "       1., 0., 0., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 0., 0., 0.,\n",
      "       1., 0., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0.,\n",
      "       0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0.,\n",
      "       1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1.,\n",
      "       1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 0.,\n",
      "       0., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 0., 1., 0., 0., 0.,\n",
      "       0., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 1., 0., 1., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0.,\n",
      "       1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 0.,\n",
      "       0., 0., 1., 1., 1., 0., 1., 0., 0., 0., 0., 0., 0.], dtype=float32), 'X': array([[1.40708268e+00, 0.00000000e+00, 0.00000000e+00, 1.73825645e+00,\n",
      "        0.00000000e+00],\n",
      "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.18376613e+00,\n",
      "        0.00000000e+00],\n",
      "       [7.77785778e-01, 2.70065755e-01, 2.15851083e-01, 1.33372879e+00,\n",
      "        2.00000000e+00],\n",
      "       [2.00000000e+00, 1.57568586e+00, 1.85029912e+00, 1.51334286e+00,\n",
      "        2.00000000e+00],\n",
      "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.08272696e+00,\n",
      "        7.24835813e-01],\n",
      "       [1.46796215e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00],\n",
      "       [3.39167058e-01, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        1.11259842e+00],\n",
      "       [1.70771122e+00, 1.56853426e+00, 2.00000000e+00, 7.81196237e-01,\n",
      "        1.09341180e+00],\n",
      "       [4.12773460e-01, 2.00000000e+00, 2.00000000e+00, 0.00000000e+00,\n",
      "        3.38881731e-01],\n",
      "       [7.00966179e-01, 0.00000000e+00, 7.52118111e-01, 1.80460346e+00,\n",
      "        1.62388098e+00],\n",
      "       [0.00000000e+00, 1.04511626e-01, 2.53960192e-01, 0.00000000e+00,\n",
      "        0.00000000e+00],\n",
      "       [1.12832499e+00, 2.10129976e-01, 0.00000000e+00, 3.72983098e-01,\n",
      "        2.00677872e-01],\n",
      "       [0.00000000e+00, 1.73114800e+00, 7.00280309e-01, 2.00000000e+00,\n",
      "        7.63763249e-01],\n",
      "       [0.00000000e+00, 2.00000000e+00, 2.00000000e+00, 1.60191238e+00,\n",
      "        2.00000000e+00],\n",
      "       [0.00000000e+00, 2.00000000e+00, 8.65847051e-01, 2.00000000e+00,\n",
      "        0.00000000e+00],\n",
      "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        7.05152035e-01],\n",
      "       [0.00000000e+00, 2.00000000e+00, 7.09068298e-01, 2.00000000e+00,\n",
      "        2.00000000e+00],\n",
      "       [1.59484065e+00, 2.00000000e+00, 0.00000000e+00, 2.00000000e+00,\n",
      "        2.33615845e-01],\n",
      "       [5.89778066e-01, 9.15844679e-01, 1.22722113e+00, 1.06739771e+00,\n",
      "        2.00000000e+00],\n",
      "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 2.00000000e+00,\n",
      "        1.29779148e+00],\n",
      "       [4.35003936e-01, 2.00000000e+00, 2.00000000e+00, 7.94807732e-01,\n",
      "        0.00000000e+00],\n",
      "       [0.00000000e+00, 0.00000000e+00, 3.55276227e-01, 0.00000000e+00,\n",
      "        0.00000000e+00],\n",
      "       [2.00000000e+00, 7.84914017e-01, 2.00000000e+00, 2.00000000e+00,\n",
      "        2.00000000e+00],\n",
      "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00],\n",
      "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00],\n",
      "       [2.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        2.00000000e+00],\n",
      "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00],\n",
      "       [0.00000000e+00, 1.66611850e-01, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00],\n",
      "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00],\n",
      "       [1.97558880e+00, 2.00000000e+00, 2.00000000e+00, 0.00000000e+00,\n",
      "        1.92915535e+00],\n",
      "       [2.00000000e+00, 2.00000000e+00, 1.15657377e+00, 2.00000000e+00,\n",
      "        8.38460922e-02],\n",
      "       [2.00000000e+00, 2.00000000e+00, 2.00000000e+00, 2.00000000e+00,\n",
      "        2.00000000e+00],\n",
      "       [2.00000000e+00, 2.00000000e+00, 1.98983595e-01, 1.80817023e-01,\n",
      "        1.76399910e+00],\n",
      "       [2.00000000e+00, 2.00000000e+00, 2.00000000e+00, 0.00000000e+00,\n",
      "        2.00000000e+00],\n",
      "       [7.97555208e-01, 1.92994952e+00, 1.59486377e+00, 1.12533593e+00,\n",
      "        5.08955777e-01],\n",
      "       [0.00000000e+00, 0.00000000e+00, 4.89389449e-01, 1.27826214e+00,\n",
      "        0.00000000e+00],\n",
      "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00],\n",
      "       [1.44821560e+00, 2.00000000e+00, 2.00000000e+00, 1.53607690e+00,\n",
      "        7.79464483e-01],\n",
      "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00],\n",
      "       [0.00000000e+00, 1.65077078e+00, 1.27199829e+00, 0.00000000e+00,\n",
      "        0.00000000e+00],\n",
      "       [0.00000000e+00, 0.00000000e+00, 3.82724255e-01, 0.00000000e+00,\n",
      "        0.00000000e+00],\n",
      "       [2.00000000e+00, 1.40172946e+00, 5.37166178e-01, 0.00000000e+00,\n",
      "        1.70997977e+00],\n",
      "       [2.00000000e+00, 1.47830141e+00, 2.00000000e+00, 2.00000000e+00,\n",
      "        4.33412313e-01],\n",
      "       [2.20526028e-02, 6.26492918e-01, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00],\n",
      "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00],\n",
      "       [3.34595770e-01, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        9.14978802e-01],\n",
      "       [0.00000000e+00, 2.59002596e-01, 1.47675276e-01, 6.96027100e-01,\n",
      "        0.00000000e+00],\n",
      "       [0.00000000e+00, 0.00000000e+00, 2.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00],\n",
      "       [1.78072977e+00, 1.86138201e+00, 7.39826918e-01, 2.00000000e+00,\n",
      "        9.44506705e-01],\n",
      "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00],\n",
      "       [2.00000000e+00, 1.66968286e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        5.63127458e-01],\n",
      "       [2.00000000e+00, 1.56810820e-01, 9.31544244e-01, 2.00000000e+00,\n",
      "        0.00000000e+00],\n",
      "       [2.00000000e+00, 0.00000000e+00, 2.00000000e+00, 2.00000000e+00,\n",
      "        1.88440049e+00],\n",
      "       [0.00000000e+00, 2.99402386e-01, 0.00000000e+00, 4.92165089e-01,\n",
      "        8.13207209e-01],\n",
      "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00],\n",
      "       [1.21892822e+00, 0.00000000e+00, 1.42722332e+00, 2.00000000e+00,\n",
      "        2.00000000e+00],\n",
      "       [1.34767890e-01, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00],\n",
      "       [2.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        1.19006455e+00],\n",
      "       [0.00000000e+00, 1.43704510e+00, 1.03181684e+00, 0.00000000e+00,\n",
      "        0.00000000e+00],\n",
      "       [0.00000000e+00, 1.20612288e+00, 2.00000000e+00, 9.40464139e-01,\n",
      "        2.00000000e+00],\n",
      "       [0.00000000e+00, 8.08546722e-01, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00],\n",
      "       [0.00000000e+00, 0.00000000e+00, 1.88013816e+00, 1.59620667e+00,\n",
      "        0.00000000e+00],\n",
      "       [2.00000000e+00, 1.64645389e-01, 0.00000000e+00, 1.30960882e+00,\n",
      "        1.64740407e+00],\n",
      "       [1.05562627e+00, 9.30695057e-01, 1.31557807e-01, 2.00000000e+00,\n",
      "        2.00000000e+00],\n",
      "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        1.88802958e+00],\n",
      "       [3.27451468e-01, 1.23370016e+00, 9.75629032e-01, 0.00000000e+00,\n",
      "        0.00000000e+00],\n",
      "       [1.04189301e+00, 7.87711680e-01, 0.00000000e+00, 2.00000000e+00,\n",
      "        0.00000000e+00],\n",
      "       [1.12955666e+00, 2.00000000e+00, 1.74005938e+00, 2.00000000e+00,\n",
      "        0.00000000e+00],\n",
      "       [2.00000000e+00, 2.00000000e+00, 0.00000000e+00, 2.00000000e+00,\n",
      "        3.93366635e-01],\n",
      "       [2.00000000e+00, 0.00000000e+00, 2.00000000e+00, 2.00000000e+00,\n",
      "        0.00000000e+00],\n",
      "       [0.00000000e+00, 2.00000000e+00, 1.23533070e+00, 2.00000000e+00,\n",
      "        0.00000000e+00],\n",
      "       [6.47083670e-02, 8.39479089e-01, 1.42307293e+00, 3.39419348e-03,\n",
      "        9.15054977e-01],\n",
      "       [0.00000000e+00, 5.88753283e-01, 8.64581704e-01, 1.61986363e+00,\n",
      "        0.00000000e+00],\n",
      "       [2.00000000e+00, 2.42727891e-01, 1.58154869e+00, 2.00000000e+00,\n",
      "        2.00000000e+00],\n",
      "       [0.00000000e+00, 0.00000000e+00, 1.96459746e+00, 2.55541027e-01,\n",
      "        0.00000000e+00],\n",
      "       [0.00000000e+00, 5.08720517e-01, 6.74001873e-01, 1.58344030e+00,\n",
      "        1.52833074e-01],\n",
      "       [2.00000000e+00, 5.61048567e-01, 7.62462854e-01, 0.00000000e+00,\n",
      "        2.00000000e+00],\n",
      "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.86636162e+00,\n",
      "        0.00000000e+00],\n",
      "       [2.00000000e+00, 2.00000000e+00, 2.00000000e+00, 2.00000000e+00,\n",
      "        2.00000000e+00],\n",
      "       [5.65483451e-01, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00],\n",
      "       [2.00000000e+00, 0.00000000e+00, 1.35802364e+00, 2.00000000e+00,\n",
      "        2.00000000e+00],\n",
      "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00],\n",
      "       [1.34284651e+00, 0.00000000e+00, 1.90241814e+00, 1.45036650e+00,\n",
      "        0.00000000e+00],\n",
      "       [0.00000000e+00, 1.96677661e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00],\n",
      "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00],\n",
      "       [0.00000000e+00, 8.67069185e-01, 0.00000000e+00, 0.00000000e+00,\n",
      "        9.02312696e-01],\n",
      "       [0.00000000e+00, 0.00000000e+00, 1.16521813e-01, 0.00000000e+00,\n",
      "        0.00000000e+00],\n",
      "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00],\n",
      "       [8.44612300e-01, 7.88207293e-01, 9.62145161e-03, 0.00000000e+00,\n",
      "        3.65843892e-01],\n",
      "       [2.00000000e+00, 2.00000000e+00, 2.00000000e+00, 0.00000000e+00,\n",
      "        2.00000000e+00],\n",
      "       [0.00000000e+00, 1.75072241e+00, 0.00000000e+00, 2.80541390e-01,\n",
      "        4.37930852e-01],\n",
      "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00],\n",
      "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 3.33608419e-01,\n",
      "        0.00000000e+00],\n",
      "       [1.51404679e+00, 1.18471050e+00, 1.41700768e+00, 5.70136607e-01,\n",
      "        0.00000000e+00],\n",
      "       [1.00266445e+00, 2.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00],\n",
      "       [2.00000000e+00, 4.73732620e-01, 0.00000000e+00, 1.70299482e+00,\n",
      "        1.24981403e+00],\n",
      "       [2.00000000e+00, 4.63716149e-01, 0.00000000e+00, 2.00000000e+00,\n",
      "        4.52427000e-01],\n",
      "       [0.00000000e+00, 2.00000000e+00, 2.00000000e+00, 1.59303403e+00,\n",
      "        0.00000000e+00],\n",
      "       [2.00000000e+00, 2.00000000e+00, 2.00000000e+00, 2.00000000e+00,\n",
      "        2.00000000e+00],\n",
      "       [1.06057227e+00, 2.00000000e+00, 1.36129594e+00, 2.00000000e+00,\n",
      "        0.00000000e+00],\n",
      "       [2.00000000e+00, 1.75892389e+00, 1.62436068e+00, 2.00000000e+00,\n",
      "        2.00000000e+00],\n",
      "       [2.00000000e+00, 2.00000000e+00, 2.00000000e+00, 2.00000000e+00,\n",
      "        2.00000000e+00],\n",
      "       [2.00000000e+00, 9.88728166e-01, 2.00000000e+00, 2.00000000e+00,\n",
      "        1.24541795e+00],\n",
      "       [0.00000000e+00, 1.01331425e+00, 0.00000000e+00, 9.85428691e-01,\n",
      "        1.36144602e+00],\n",
      "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00],\n",
      "       [0.00000000e+00, 1.59968078e-01, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00],\n",
      "       [0.00000000e+00, 0.00000000e+00, 6.64958894e-01, 0.00000000e+00,\n",
      "        0.00000000e+00],\n",
      "       [4.65162456e-01, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00],\n",
      "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00],\n",
      "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00],\n",
      "       [0.00000000e+00, 2.00000000e+00, 1.47312617e+00, 1.89382100e+00,\n",
      "        1.55113661e+00],\n",
      "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00],\n",
      "       [0.00000000e+00, 1.03555393e+00, 0.00000000e+00, 1.24066293e+00,\n",
      "        1.10701251e+00],\n",
      "       [0.00000000e+00, 5.54629385e-01, 3.73041898e-01, 6.16075993e-01,\n",
      "        0.00000000e+00],\n",
      "       [1.03062201e+00, 8.14584851e-01, 1.48583329e+00, 6.73878014e-01,\n",
      "        0.00000000e+00],\n",
      "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        2.00000000e+00],\n",
      "       [0.00000000e+00, 2.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00],\n",
      "       [2.00000000e+00, 0.00000000e+00, 0.00000000e+00, 2.00000000e+00,\n",
      "        0.00000000e+00],\n",
      "       [3.13817203e-01, 6.02867782e-01, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00],\n",
      "       [2.00000000e+00, 2.00000000e+00, 2.00000000e+00, 2.00000000e+00,\n",
      "        2.00000000e+00],\n",
      "       [2.00000000e+00, 2.00000000e+00, 2.00000000e+00, 2.00000000e+00,\n",
      "        2.00000000e+00],\n",
      "       [9.15068030e-01, 2.00000000e+00, 2.03233793e-01, 2.00000000e+00,\n",
      "        0.00000000e+00],\n",
      "       [2.00000000e+00, 0.00000000e+00, 2.00000000e+00, 2.00000000e+00,\n",
      "        1.42748976e+00],\n",
      "       [9.04965699e-01, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00],\n",
      "       [6.45019412e-01, 7.96776891e-01, 1.97815418e+00, 2.00000000e+00,\n",
      "        8.72486830e-01],\n",
      "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 5.73989809e-01,\n",
      "        0.00000000e+00],\n",
      "       [2.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00],\n",
      "       [5.50576866e-01, 1.55027103e+00, 0.00000000e+00, 7.51407623e-01,\n",
      "        2.52558678e-01],\n",
      "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00],\n",
      "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00],\n",
      "       [7.47357905e-01, 2.00000000e+00, 0.00000000e+00, 1.06721151e+00,\n",
      "        2.00000000e+00],\n",
      "       [8.70571136e-01, 2.00000000e+00, 6.89241290e-01, 2.00000000e+00,\n",
      "        1.17069805e+00],\n",
      "       [0.00000000e+00, 0.00000000e+00, 3.01747084e-01, 0.00000000e+00,\n",
      "        0.00000000e+00],\n",
      "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 3.22404206e-01,\n",
      "        0.00000000e+00],\n",
      "       [2.00000000e+00, 7.50878751e-01, 2.00000000e+00, 2.93851823e-01,\n",
      "        7.35067368e-01],\n",
      "       [1.55571663e+00, 1.35319638e+00, 2.00000000e+00, 2.00000000e+00,\n",
      "        2.00000000e+00],\n",
      "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 2.00000000e+00,\n",
      "        0.00000000e+00],\n",
      "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00],\n",
      "       [6.62241220e-01, 2.00000000e+00, 1.20093977e+00, 2.00000000e+00,\n",
      "        8.18934739e-01],\n",
      "       [6.66651249e-01, 2.00000000e+00, 6.37375414e-01, 1.26272571e+00,\n",
      "        1.90064466e+00],\n",
      "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00],\n",
      "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00],\n",
      "       [0.00000000e+00, 1.99972832e+00, 9.96960998e-02, 0.00000000e+00,\n",
      "        0.00000000e+00],\n",
      "       [0.00000000e+00, 0.00000000e+00, 2.00000000e+00, 0.00000000e+00,\n",
      "        2.00000000e+00],\n",
      "       [1.06840396e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00],\n",
      "       [9.70945299e-01, 1.70149839e+00, 0.00000000e+00, 3.05742979e-01,\n",
      "        2.02651069e-01],\n",
      "       [0.00000000e+00, 0.00000000e+00, 1.72491312e+00, 7.92940259e-01,\n",
      "        0.00000000e+00],\n",
      "       [0.00000000e+00, 1.96862066e+00, 2.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00],\n",
      "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        9.06343818e-01],\n",
      "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.28407216e+00,\n",
      "        2.00000000e+00],\n",
      "       [0.00000000e+00, 1.79767597e+00, 8.02260637e-01, 2.00000000e+00,\n",
      "        0.00000000e+00],\n",
      "       [0.00000000e+00, 3.20282996e-01, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00],\n",
      "       [0.00000000e+00, 8.59411478e-01, 3.96202683e-01, 1.05344689e+00,\n",
      "        1.63720939e-02],\n",
      "       [2.78224498e-01, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00],\n",
      "       [1.15862548e+00, 2.00000000e+00, 2.00000000e+00, 9.31298614e-01,\n",
      "        2.00000000e+00],\n",
      "       [2.00000000e+00, 2.00000000e+00, 5.47882140e-01, 2.00000000e+00,\n",
      "        1.13768792e+00],\n",
      "       [0.00000000e+00, 0.00000000e+00, 2.00000000e+00, 2.00000000e+00,\n",
      "        8.30080628e-01],\n",
      "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 2.00000000e+00,\n",
      "        2.00000000e+00],\n",
      "       [0.00000000e+00, 0.00000000e+00, 7.57919669e-01, 1.10891151e+00,\n",
      "        5.64438403e-01],\n",
      "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.53420717e-01,\n",
      "        6.93358183e-01],\n",
      "       [2.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        1.21446419e+00],\n",
      "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00],\n",
      "       [1.19719660e+00, 4.83804792e-01, 1.28398597e+00, 1.19492388e+00,\n",
      "        0.00000000e+00],\n",
      "       [1.32544172e+00, 5.14995396e-01, 2.00000000e+00, 7.63519585e-01,\n",
      "        0.00000000e+00],\n",
      "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00],\n",
      "       [6.35706633e-02, 2.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        1.66386104e+00],\n",
      "       [2.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.62980115e+00,\n",
      "        2.00000000e+00],\n",
      "       [8.43644679e-01, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00],\n",
      "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00],\n",
      "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00],\n",
      "       [2.00000000e+00, 1.28462434e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        2.00000000e+00],\n",
      "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00],\n",
      "       [2.00000000e+00, 0.00000000e+00, 9.28284526e-01, 4.73088562e-01,\n",
      "        2.00000000e+00],\n",
      "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00],\n",
      "       [0.00000000e+00, 3.43828648e-02, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00],\n",
      "       [1.24813116e+00, 1.95255864e+00, 1.02589321e+00, 2.00000000e+00,\n",
      "        7.34348476e-01],\n",
      "       [1.95935595e+00, 0.00000000e+00, 3.35259199e-01, 0.00000000e+00,\n",
      "        0.00000000e+00],\n",
      "       [2.00000000e+00, 9.12107766e-01, 0.00000000e+00, 2.00000000e+00,\n",
      "        2.00000000e+00],\n",
      "       [0.00000000e+00, 0.00000000e+00, 2.00000000e+00, 2.00000000e+00,\n",
      "        2.48803012e-02],\n",
      "       [0.00000000e+00, 1.67058051e+00, 2.85656279e-04, 1.47371471e+00,\n",
      "        0.00000000e+00],\n",
      "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00],\n",
      "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00],\n",
      "       [0.00000000e+00, 0.00000000e+00, 7.01855838e-01, 0.00000000e+00,\n",
      "        1.02670205e+00],\n",
      "       [1.62172601e-01, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        5.78763068e-01],\n",
      "       [2.00000000e+00, 2.00000000e+00, 2.00000000e+00, 2.00000000e+00,\n",
      "        2.00000000e+00],\n",
      "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00],\n",
      "       [0.00000000e+00, 0.00000000e+00, 2.92293906e-01, 2.00000000e+00,\n",
      "        8.27061951e-01],\n",
      "       [1.95915282e+00, 1.47902787e+00, 1.00102580e+00, 0.00000000e+00,\n",
      "        2.00000000e+00],\n",
      "       [0.00000000e+00, 6.90175295e-01, 1.58950889e+00, 0.00000000e+00,\n",
      "        0.00000000e+00],\n",
      "       [2.00000000e+00, 5.62337160e-01, 2.00000000e+00, 2.00000000e+00,\n",
      "        2.00000000e+00],\n",
      "       [2.00000000e+00, 5.17276764e-01, 8.14482987e-01, 0.00000000e+00,\n",
      "        2.36296058e-02],\n",
      "       [1.05346668e+00, 6.67163193e-01, 0.00000000e+00, 1.50483096e+00,\n",
      "        0.00000000e+00],\n",
      "       [1.34852946e+00, 2.00000000e+00, 0.00000000e+00, 1.70482934e+00,\n",
      "        1.56871951e+00],\n",
      "       [0.00000000e+00, 2.00000000e+00, 2.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00],\n",
      "       [0.00000000e+00, 1.42447793e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00],\n",
      "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.88237166e+00,\n",
      "        4.48243827e-01],\n",
      "       [0.00000000e+00, 2.80447662e-01, 0.00000000e+00, 0.00000000e+00,\n",
      "        1.49887156e+00],\n",
      "       [0.00000000e+00, 2.00000000e+00, 2.00000000e+00, 1.46007431e+00,\n",
      "        8.69479358e-01],\n",
      "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.09300840e+00,\n",
      "        0.00000000e+00],\n",
      "       [0.00000000e+00, 8.96516740e-01, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00]], dtype=float32), 'T': array([5.50461113e-01, 2.62295258e+02, 4.03058715e-03, 2.40973064e-09,\n",
      "       1.12498283e+00, 5.95864630e+00, 9.88003612e-01, 1.38498336e-01,\n",
      "       3.47436500e+00, 2.96098779e-06, 4.05000244e+02, 6.64601669e+01,\n",
      "       1.92752135e+00, 2.52785417e-03, 1.27858937e+00, 9.07511444e+01,\n",
      "       1.85982190e-05, 3.71884927e-02, 2.15385699e-05, 1.45755485e-02,\n",
      "       4.12782937e-01, 1.28140181e-01, 1.12757892e-09, 2.60434389e-01,\n",
      "       1.49843826e+02, 2.79939473e-01, 2.58833923e+02, 2.28791265e-03,\n",
      "       6.54849243e+02, 1.79843628e-03, 1.84381428e+01, 6.60513473e-13,\n",
      "       4.84412238e-02, 1.66674272e-05, 3.55395768e-03, 9.29521656e+00,\n",
      "       1.33009082e+03, 1.25690654e-01, 3.54764247e+00, 1.20116863e+01,\n",
      "       3.67568803e+00, 2.61121728e-02, 2.63517859e-06, 4.35396652e+01,\n",
      "       6.48445654e+00, 2.16996441e+01, 9.22599106e+01, 9.14248943e+00,\n",
      "       8.90789852e-02, 2.41658783e+01, 1.64168091e+01, 2.64828053e+01,\n",
      "       4.76918105e-09, 5.08828087e+01, 3.42369919e+01, 9.57644275e-08,\n",
      "       8.14836884e+00, 3.28439474e+00, 1.34338699e+02, 5.83025301e-03,\n",
      "       6.76647139e+00, 6.07579015e-03, 3.37322503e-02, 8.12082216e-02,\n",
      "       3.32286162e-03, 7.36571670e-01, 5.15593605e+01, 7.21750259e-02,\n",
      "       9.14393738e-02, 5.64025545e+00, 6.58726740e+00, 8.39918213e+01,\n",
      "       3.30016685e+00, 4.90940465e-07, 6.22064173e-01, 7.27275314e+01,\n",
      "       7.51146581e-03, 4.21762556e-01, 3.89786874e-04, 5.15762758e+00,\n",
      "       2.10498460e-03, 1.20871866e+00, 3.77488881e-02, 1.75795929e+02,\n",
      "       8.09746206e-01, 2.55147517e-01, 2.27513794e+03, 3.46166954e+01,\n",
      "       1.43293972e+01, 9.44160449e-04, 4.28426695e+00, 2.43420696e+01,\n",
      "       2.04766953e+02, 7.73606396e+00, 1.25869171e+02, 7.95331150e-02,\n",
      "       1.21010733e+00, 2.28182208e-02, 2.47051435e-10, 9.32751560e+00,\n",
      "       1.77873138e-09, 2.09553356e-04, 4.90941945e-03, 1.47872496e+00,\n",
      "       5.35075760e+01, 3.86481056e+01, 1.43299356e-01, 3.72865906e+02,\n",
      "       6.70650101e+01, 2.92418003e+01, 5.32943709e-03, 7.80854645e+01,\n",
      "       1.70370350e+01, 1.07948989e-01, 8.57190881e-03, 5.31492475e-03,\n",
      "       1.15972046e+02, 1.03519611e+01, 5.08903694e+01, 2.31321490e-10,\n",
      "       1.00272714e-10, 8.78249388e-03, 2.73856967e-05, 2.93396568e+01,\n",
      "       1.79471485e-02, 6.28474655e+01, 5.07276058e+00, 3.64231372e+00,\n",
      "       4.76843724e-03, 3.60538559e+01, 3.76267635e-05, 3.88013050e-02,\n",
      "       1.50650177e+02, 1.90694870e+02, 9.69275284e+00, 1.23420899e-10,\n",
      "       1.18263531e+01, 8.76049744e+02, 1.46814436e-01, 8.10241690e-05,\n",
      "       3.08915691e+01, 4.30806152e+02, 2.49607239e+02, 3.16411071e-03,\n",
      "       4.37049408e+02, 4.97402847e-02, 1.34493847e+01, 8.17931671e+01,\n",
      "       6.47395372e+00, 4.54682420e-04, 3.63948822e-01, 2.93727458e-01,\n",
      "       2.46200886e+01, 3.90879750e+00, 3.84753197e-03, 1.04336580e-02,\n",
      "       1.23539828e-02, 3.58062377e-03, 1.30651307e+00, 3.01986128e-01,\n",
      "       1.69351368e+01, 1.49541264e+01, 4.37316170e+01, 2.91779423e+01,\n",
      "       5.66322899e+00, 1.48807883e+00, 4.95386161e-02, 6.73537369e+01,\n",
      "       5.70781784e+01, 4.08539856e+02, 2.15388165e-04, 1.59315690e-02,\n",
      "       3.39824357e-03, 7.86003036e+01, 7.36794281e+01, 3.51007581e-01,\n",
      "       2.22585358e+02, 2.57931551e-05, 1.17938267e-02, 3.98391294e+00,\n",
      "       9.07064915e+00, 4.66592598e+00, 1.04803583e-02, 6.15715837e+00,\n",
      "       2.20024651e-10, 9.27843323e+02, 4.91637468e-01, 1.82052888e-02,\n",
      "       2.00319580e+02, 1.45193128e-11, 3.10689449e+01, 2.47876797e+01,\n",
      "       8.50829482e-02, 8.58273089e-01, 2.56280460e+01, 4.08826141e+01,\n",
      "       9.60977256e-01, 5.48452437e-02, 1.70801716e+01, 8.68391454e-01],\n",
      "      dtype=float32), 'U': array([3.9303911e+00, 9.1444159e+00, 5.7754164e+00, 1.5134621e+00,\n",
      "       9.3394814e+00, 7.2165403e+00, 6.8907199e+00, 1.8882295e+00,\n",
      "       7.8357921e+00, 2.8819537e+00, 1.6449773e-01, 4.2181352e-01,\n",
      "       8.4017572e+00, 7.2933655e+00, 1.3674583e+00, 9.1876059e+00,\n",
      "       2.2956891e+00, 6.7057457e+00, 7.8381209e+00, 6.8645447e-01,\n",
      "       1.0302081e+00, 6.0998344e+00, 1.6323742e+00, 2.0262301e+00,\n",
      "       3.1841607e+00, 1.2487766e+00, 8.1653976e+00, 5.5117478e+00,\n",
      "       1.1907637e+00, 8.5806255e+00, 6.6924157e+00, 1.5908324e+00,\n",
      "       4.7635179e+00, 9.6528568e+00, 8.6112461e+00, 9.2706118e+00,\n",
      "       9.1430178e+00, 1.6129136e-01, 4.7595391e+00, 3.3639853e+00,\n",
      "       9.0558033e+00, 3.1282682e+00, 5.3622460e+00, 9.4756861e+00,\n",
      "       7.9731040e+00, 3.2113967e+00, 4.3486528e+00, 4.8282261e+00,\n",
      "       6.4016509e+00, 6.8857026e+00, 1.6897918e+00, 5.9869022e+00,\n",
      "       8.8117828e+00, 5.4137726e+00, 7.6958165e+00, 8.1363201e-01,\n",
      "       4.0154905e+00, 5.2334976e+00, 8.9491260e-01, 1.1825032e-02,\n",
      "       8.9441423e+00, 9.7499008e+00, 4.4314523e+00, 7.3226862e+00,\n",
      "       7.7169061e-01, 4.6199350e+00, 3.1983871e+00, 5.5188866e+00,\n",
      "       7.3912854e+00, 4.0992374e+00, 2.6144559e+00, 9.8951664e+00,\n",
      "       5.1039248e+00, 7.1371641e+00, 9.4033337e+00, 1.9884191e-01,\n",
      "       7.5850258e+00, 7.9214725e+00, 5.9267101e+00, 1.5380510e+00,\n",
      "       9.1236286e+00, 3.5562322e+00, 7.8529558e+00, 7.3294818e-01,\n",
      "       2.3775194e+00, 2.5860829e+00, 7.2067161e+00, 2.6725392e+00,\n",
      "       1.1601275e+00, 9.2632837e+00, 5.0693212e+00, 2.9384005e+00,\n",
      "       4.4281964e+00, 9.7732611e+00, 5.2335339e+00, 3.2531679e+00,\n",
      "       4.6898451e+00, 7.0184436e+00, 9.4644156e+00, 5.9929204e+00,\n",
      "       3.1215379e+00, 7.3973699e+00, 2.6132932e+00, 6.6829290e+00,\n",
      "       3.7873542e-01, 1.8962927e+00, 4.6006751e+00, 3.8874819e+00,\n",
      "       9.6984625e+00, 2.1598039e+00, 3.8229854e+00, 1.3405106e+00,\n",
      "       9.8454790e+00, 8.2472334e+00, 7.4492912e+00, 5.8319554e+00,\n",
      "       5.5870805e+00, 6.1306162e+00, 4.0816106e-03, 7.4926534e+00,\n",
      "       3.6966841e+00, 2.8462548e+00, 3.5867631e+00, 2.0875432e+00,\n",
      "       2.5252292e+00, 1.6081343e+00, 3.9660196e+00, 7.4229875e+00,\n",
      "       1.9808873e+00, 5.9730000e+00, 3.5387156e+00, 9.6192913e+00,\n",
      "       3.4950771e+00, 3.4694436e+00, 6.9517698e+00, 8.7938080e+00,\n",
      "       5.2457843e+00, 3.1960955e+00, 1.5867685e-01, 4.8055048e+00,\n",
      "       7.5713205e+00, 7.9433286e-01, 2.6912985e+00, 2.0799062e+00,\n",
      "       4.0495834e+00, 6.7286987e+00, 7.4607581e-01, 7.4884911e+00,\n",
      "       8.6901875e+00, 1.3607252e+00, 8.9633703e+00, 4.7617445e+00,\n",
      "       3.9372013e+00, 3.5595400e+00, 8.7946024e+00, 6.1332393e+00,\n",
      "       6.4393253e+00, 2.7254341e+00, 3.0970111e+00, 4.1339202e+00,\n",
      "       5.8705645e+00, 9.5952063e+00, 1.7904187e+00, 6.6439533e+00,\n",
      "       1.2187804e+00, 8.2667961e+00, 6.5190067e+00, 6.5429587e+00,\n",
      "       7.3790202e+00, 7.9453359e+00, 6.8876907e-02, 4.5538321e+00,\n",
      "       9.3413172e+00, 7.0289588e+00, 3.7169905e+00, 6.4204955e+00,\n",
      "       4.0622706e+00, 9.5949621e+00, 8.7735319e+00, 1.9013294e+00,\n",
      "       5.2851734e+00, 6.8620019e+00, 1.7836325e+00, 3.8842599e+00,\n",
      "       9.8523159e+00, 3.2236409e+00, 5.3789597e+00, 3.2478004e+00,\n",
      "       9.8163147e+00, 6.2404490e-01, 8.7674999e+00, 7.0442929e+00,\n",
      "       7.3409991e+00, 5.3384042e+00, 8.9254534e-01, 7.0911512e+00,\n",
      "       7.9011931e+00, 5.1970453e+00, 5.6678486e+00, 4.6255894e+00],\n",
      "      dtype=float32), 'De': array([1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0., 1., 1., 1.,\n",
      "       1., 0., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0., 0., 1., 0., 0.,\n",
      "       0., 1., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1.,\n",
      "       1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1.,\n",
      "       1., 0., 0., 0., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1.,\n",
      "       1., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 1., 1., 0., 0., 0.,\n",
      "       1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 0., 0., 0., 1.,\n",
      "       0., 0., 1., 1., 0., 0., 0., 1., 0., 1., 0., 0., 1., 1., 1., 1., 0.,\n",
      "       0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0.,\n",
      "       1., 1., 1., 0., 0., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1.,\n",
      "       1., 0., 1., 0., 0., 1., 1., 0., 0., 1., 1., 0., 1.], dtype=float32), 'g_X': array([-1.0742263 , -1.1496496 ,  2.1742156 ,  3.7420475 , -0.6332446 ,\n",
      "       -1.41      , -0.38887346,  0.88317287, -1.0265921 ,  1.2253317 ,\n",
      "       -1.41      , -1.0958378 , -0.22543049,  3.7051892 , -0.6689504 ,\n",
      "       -0.8979228 ,  2.402121  , -0.5550228 ,  2.5755084 ,  0.28680494,\n",
      "       -0.2336779 , -1.41      ,  4.4013176 , -1.41      , -1.41      ,\n",
      "        1.784528  , -1.41      , -1.41      , -1.41      ,  1.9293981 ,\n",
      "        0.06876625,  4.550732  ,  1.4650564 ,  2.184528  ,  0.13681725,\n",
      "       -1.0589924 , -1.41      ,  1.3668133 , -1.41      , -1.41      ,\n",
      "       -1.41      ,  1.1892954 ,  1.5713557 , -1.3864919 , -1.41      ,\n",
      "       -0.66163886, -1.2301091 , -1.41      ,  0.3797702 , -1.41      ,\n",
      "       -0.6664433 , -0.49790472,  3.7474074 , -0.6490261 , -1.41      ,\n",
      "        3.1692154 , -1.41      , -0.26635328, -1.41      ,  2.945968  ,\n",
      "       -1.41      ,  0.3186326 ,  1.080534  ,  2.3576248 ,  1.3931694 ,\n",
      "       -1.2828816 , -0.8626097 ,  0.7707144 , -0.40281507,  0.9562041 ,\n",
      "       -0.28077498, -0.61208194, -0.7862466 ,  3.5407298 , -1.0875702 ,\n",
      "       -0.83123004,  1.9963862 , -1.0589855 ,  4.550732  , -1.41      ,\n",
      "        3.0728462 , -1.41      ,  0.20103566, -1.41      , -1.41      ,\n",
      "       -0.677351  , -1.41      , -1.41      , -1.0259504 ,  2.184528  ,\n",
      "       -1.0528234 , -1.41      , -1.3140372 , -0.7055579 , -1.1267807 ,\n",
      "        0.3609761 , -0.5651278 ,  0.50064355,  4.550732  ,  0.17405035,\n",
      "        3.8451245 ,  4.550732  ,  2.4746416 ,  0.26952732, -1.41      ,\n",
      "       -1.41      , -1.41      , -1.41      , -1.41      , -1.41      ,\n",
      "        1.8300526 , -1.41      , -0.12842272, -1.2285664 , -0.6831038 ,\n",
      "        1.784528  , -1.41      , -1.043796  , -1.323008  ,  4.550732  ,\n",
      "        4.550732  , -0.75257885,  2.5403154 , -1.41      ,  1.7525568 ,\n",
      "       -1.2587955 , -1.41      , -0.894761  , -1.41      , -1.41      ,\n",
      "        2.271112  ,  0.56975675, -1.41      , -1.3168495 , -0.24236992,\n",
      "        4.4409175 , -1.043796  , -1.41      ,  0.54154575,  2.0664754 ,\n",
      "       -1.41      , -1.41      , -1.41      ,  1.784528  , -1.41      ,\n",
      "       -0.9516883 , -0.6255672 , -1.41      , -0.672372  ,  2.059848  ,\n",
      "       -0.72198486, -1.41      , -1.120565  , -1.41      ,  3.2396746 ,\n",
      "        0.5660652 ,  1.6029559 ,  2.150732  , -0.6227946 , -0.8622116 ,\n",
      "       -0.22575557, -1.41      , -0.5032454 , -0.29213774, -1.41      ,\n",
      "        0.8011421 ,  2.1068308 , -1.41      , -1.41      , -1.41      ,\n",
      "        2.1051056 , -1.41      ,  2.015565  , -1.41      , -1.41      ,\n",
      "        0.3367154 , -1.41      ,  2.420859  ,  0.9688003 , -1.108093  ,\n",
      "       -1.41      , -1.41      , -0.5140784 , -1.0180848 ,  4.550732  ,\n",
      "       -1.41      , -0.35778266,  2.1249774 , -1.41      ,  4.3628335 ,\n",
      "       -1.1946185 , -0.9362559 ,  1.1503828 , -1.41      , -1.41      ,\n",
      "       -0.7743487 ,  0.3283174 ,  1.0429723 , -1.1637992 , -1.41      ],\n",
      "      dtype=float32), 'h_X': array([-1.2202964 , -1.2443734 ,  1.9761631 ,  5.029128  , -1.0339792 ,\n",
      "       -1.31      , -0.8972348 ,  0.20036292, -1.2039181 ,  0.60606086,\n",
      "       -1.31      , -1.227428  , -0.7924451 ,  4.94607   , -1.0519592 ,\n",
      "       -1.1551399 ,  2.3588777 , -0.9928073 ,  2.663957  , -0.3948096 ,\n",
      "       -0.79798883, -1.31      ,  6.6065464 , -1.31      , -1.31      ,\n",
      "        1.3699075 , -1.31      , -1.31      , -1.31      ,  1.5881956 ,\n",
      "       -0.57689685,  6.988212  ,  0.9182012 ,  1.993032  , -0.52210784,\n",
      "       -1.2151573 , -1.31      ,  0.78750104, -1.31      , -1.31      ,\n",
      "       -1.31      ,  0.5611264 ,  1.0639675 , -1.3051878 , -1.31      ,\n",
      "       -1.0483189 , -1.2675496 , -1.31      , -0.3113905 , -1.31      ,\n",
      "       -1.0507133 , -0.9611974 ,  5.0412517 , -1.041989  , -1.31      ,\n",
      "        3.7996857 , -1.31      , -0.8196851 , -1.31      ,  3.3560848 ,\n",
      "       -1.31      , -0.36663935,  0.42865872,  2.282524  ,  0.8221857 ,\n",
      "       -1.2813445 , -1.1405947 ,  0.07724595, -0.90567875,  0.28302518,\n",
      "       -0.82912517, -1.0230818 , -1.1074357 ,  4.582091  , -1.2247218 ,\n",
      "       -1.127251  ,  1.6919707 , -1.2151549 ,  6.988212  , -1.31      ,\n",
      "        3.6057513 , -1.31      , -0.46870568, -1.31      , -1.31      ,\n",
      "       -1.0561153 , -1.31      , -1.31      , -1.2036912 ,  1.993032  ,\n",
      "       -1.2130497 , -1.31      , -1.2889657 , -1.0698638 , -1.2373135 ,\n",
      "       -0.3285335 , -0.9982637 , -0.19775952,  6.988212  , -0.49134684,\n",
      "        5.2642913 ,  6.988212  ,  2.4850163 , -0.40993214, -1.31      ,\n",
      "       -1.31      , -1.31      , -1.31      , -1.31      , -1.31      ,\n",
      "        1.4375986 , -1.31      , -0.7251965 , -1.2671297 , -1.0589452 ,\n",
      "        1.3699075 , -1.31      , -1.209938  , -1.2910881 ,  6.988212  ,\n",
      "        6.988212  , -1.0920752 ,  2.6010616 , -1.31      ,  1.3228644 ,\n",
      "       -1.2751865 , -1.31      , -1.153858  , -1.31      , -1.31      ,\n",
      "        2.1363397 , -0.13016127, -1.31      , -1.2896345 , -0.803802  ,\n",
      "        6.706831  , -1.209938  , -1.31      , -0.15798469,  1.8024712 ,\n",
      "       -1.31      , -1.31      , -1.31      ,  1.3699075 , -1.31      ,\n",
      "       -1.1763277 , -1.0300465 , -1.31      , -1.0536554 ,  1.7919387 ,\n",
      "       -1.077724  , -1.31      , -1.2353585 , -1.31      ,  3.9438295 ,\n",
      "       -0.13382022,  1.1081718 ,  1.9379091 , -1.0286205 , -1.140428  ,\n",
      "       -0.7926642 , -1.31      , -0.9642083 , -0.83650434, -1.31      ,\n",
      "        0.11005832,  1.8669859 , -1.31      , -1.31      , -1.31      ,\n",
      "        1.8642145 , -1.31      ,  1.7220122 , -1.31      , -1.31      ,\n",
      "       -0.35045397, -1.31      ,  2.3912683 ,  0.29749823, -1.231389  ,\n",
      "       -1.31      , -1.31      , -0.9702805 , -1.2008975 ,  6.988212  ,\n",
      "       -1.31      , -0.87812424,  1.8962083 , -1.31      ,  6.509688  ,\n",
      "       -1.2576458 , -1.1703645 ,  0.5131886 , -1.31      , -1.31      ,\n",
      "       -1.1020592 , -0.35798705,  0.38400918, -1.2486368 , -1.31      ],\n",
      "      dtype=float32), 'g_X_C': array([-1.0742263 , -1.1496496 ,  2.1742156 ,  8.771175  , -0.6332446 ,\n",
      "       -1.41      , -1.2861083 ,  1.0835358 , -2.2305102 ,  1.8313925 ,\n",
      "       -2.72      , -2.3232658 , -1.0178756 ,  3.7051892 , -1.7209095 ,\n",
      "       -2.0530627 ,  2.402121  , -1.5478301 ,  5.2394657 , -0.10800467,\n",
      "       -0.2336779 , -2.72      , 11.007864  , -1.41      , -1.41      ,\n",
      "        1.784528  , -2.72      , -1.41      , -2.72      ,  3.5175936 ,\n",
      "       -0.50813055, 11.538944  ,  1.4650564 ,  4.17756   , -0.3852906 ,\n",
      "       -1.0589924 , -2.72      ,  1.3668133 , -1.41      , -2.72      ,\n",
      "       -1.41      ,  1.7504218 ,  1.5713557 , -1.3864919 , -2.72      ,\n",
      "       -0.66163886, -2.4976587 , -1.41      ,  0.3797702 , -1.41      ,\n",
      "       -1.7171566 , -0.49790472,  8.788659  , -1.6910151 , -2.72      ,\n",
      "        6.968901  , -1.41      , -1.0860384 , -1.41      ,  2.945968  ,\n",
      "       -2.72      , -0.04800676,  1.5091927 ,  2.3576248 ,  2.2153552 ,\n",
      "       -1.2828816 , -0.8626097 ,  0.84796035, -0.40281507,  0.9562041 ,\n",
      "       -1.1099001 , -0.61208194, -0.7862466 ,  8.122821  , -2.312292  ,\n",
      "       -0.83123004,  1.9963862 , -2.2741404 ,  4.550732  , -1.41      ,\n",
      "        3.0728462 , -1.41      ,  0.20103566, -2.72      , -1.41      ,\n",
      "       -1.7334663 , -2.72      , -1.41      , -2.2296417 ,  4.17756   ,\n",
      "       -1.0528234 , -1.41      , -1.3140372 , -0.7055579 , -2.3640943 ,\n",
      "        0.0324426 , -0.5651278 ,  0.302884  , 11.538944  ,  0.17405035,\n",
      "        9.109416  ,  4.550732  ,  2.4746416 ,  0.26952732, -2.72      ,\n",
      "       -1.41      , -1.41      , -2.72      , -1.41      , -1.41      ,\n",
      "        1.8300526 , -2.72      , -0.12842272, -1.2285664 , -1.742049  ,\n",
      "        1.784528  , -2.72      , -1.043796  , -1.323008  , 11.538944  ,\n",
      "       11.538944  , -0.75257885,  5.141377  , -2.72      ,  1.7525568 ,\n",
      "       -1.2587955 , -2.72      , -2.048619  , -1.41      , -1.41      ,\n",
      "        4.4074516 ,  0.56975675, -1.41      , -1.3168495 , -1.0461719 ,\n",
      "       11.147749  , -1.043796  , -2.72      ,  0.54154575,  3.8689466 ,\n",
      "       -2.72      , -2.72      , -1.41      ,  3.1544356 , -2.72      ,\n",
      "       -0.9516883 , -1.6556137 , -2.72      , -0.672372  ,  2.059848  ,\n",
      "       -0.72198486, -1.41      , -1.120565  , -1.41      ,  3.2396746 ,\n",
      "        0.5660652 ,  1.6029559 ,  2.150732  , -1.6514151 , -0.8622116 ,\n",
      "       -1.0184197 , -2.72      , -1.4674537 , -1.1286421 , -1.41      ,\n",
      "        0.9112004 ,  2.1068308 , -1.41      , -2.72      , -2.72      ,\n",
      "        3.96932   , -2.72      ,  2.015565  , -2.72      , -1.41      ,\n",
      "       -0.01373857, -1.41      ,  4.8121276 ,  0.9688003 , -1.108093  ,\n",
      "       -1.41      , -1.41      , -1.4843589 , -1.0180848 , 11.538944  ,\n",
      "       -2.72      , -0.35778266,  2.1249774 , -2.72      , 10.872521  ,\n",
      "       -1.1946185 , -0.9362559 ,  1.6635714 , -2.72      , -1.41      ,\n",
      "       -1.8764079 ,  0.3283174 ,  1.4269816 , -1.1637992 , -1.41      ],\n",
      "      dtype=float32), 'Z_2': array([1.9392507, 1.5      , 1.6690133, 2.4726415, 1.5      , 1.5      ,\n",
      "       2.5      , 2.5      , 2.5      , 2.5      , 2.046046 , 2.5      ,\n",
      "       2.5      , 1.5      , 2.3754332, 2.5      , 1.5      , 2.374506 ,\n",
      "       2.5      , 2.5      , 1.9777818, 2.5      , 2.5      , 1.7506653,\n",
      "       1.5      , 1.6730317, 2.133939 , 1.6188107, 2.024825 , 2.5      ,\n",
      "       2.5      , 2.5      , 1.5      , 2.0096312, 2.5      , 1.5      ,\n",
      "       2.5      , 1.5      , 1.5      , 2.5      , 1.5      , 2.5      ,\n",
      "       1.5      , 1.5      , 2.0295556, 1.925957 , 2.5      , 1.8311167,\n",
      "       1.679741 , 1.5      , 2.261458 , 1.5      , 2.5      , 2.1922238,\n",
      "       2.5      , 2.5      , 1.5      , 2.5      , 1.5      , 1.5      ,\n",
      "       2.5      , 2.4425044, 2.4379313, 1.909217 , 2.1770403, 1.5      ,\n",
      "       1.5      , 2.5      , 1.5      , 1.5      , 2.5      , 1.9440911,\n",
      "       1.5      , 2.2827597, 2.5      , 1.5      , 1.5      , 2.105304 ,\n",
      "       1.5      , 1.6324434, 1.5      , 1.5      , 1.9372317, 2.1679904,\n",
      "       1.5      , 2.5      , 2.5      , 1.7584982, 2.1284997, 2.5      ,\n",
      "       1.5      , 1.5      , 1.5517908, 1.8856274, 2.5      , 2.1630707,\n",
      "       1.5      , 2.5      , 2.5      , 1.5      , 2.455508 , 1.5      ,\n",
      "       1.5      , 1.5      , 2.5      , 1.5      , 1.856555 , 2.4546025,\n",
      "       1.5      , 1.6497233, 1.8008815, 2.5      , 1.5      , 1.9192638,\n",
      "       2.1434412, 1.657356 , 2.5      , 1.9326899, 1.5      , 2.5      ,\n",
      "       2.5      , 1.5      , 2.5      , 2.5      , 1.9115916, 1.5      ,\n",
      "       2.5      , 2.5      , 1.5      , 1.5      , 2.5      , 1.5      ,\n",
      "       1.5      , 1.6772969, 2.133299 , 2.5      , 1.5893272, 2.5      ,\n",
      "       1.5056401, 2.188155 , 2.5      , 2.0741074, 1.5      , 2.5      ,\n",
      "       2.2550147, 1.5      , 2.5      , 2.5      , 1.5      , 1.5      ,\n",
      "       1.5      , 1.8103373, 1.5      , 1.8551965, 1.5      , 1.9797593,\n",
      "       1.5      , 1.5981642, 2.5      , 1.9673058, 2.5      , 2.3709912,\n",
      "       2.5      , 2.1425645, 1.8539332, 2.5      , 1.5      , 1.5      ,\n",
      "       2.5      , 2.1703162, 2.5      , 2.0701516, 1.946878 , 2.353945 ,\n",
      "       1.5      , 2.5      , 1.6884353, 2.5      , 1.5      , 1.5      ,\n",
      "       1.9266506, 1.7739148, 2.5      , 1.5      , 2.5      , 2.1469097,\n",
      "       1.5      , 1.9413642, 2.5      , 2.1512272, 1.5      , 1.5      ,\n",
      "       2.5      , 2.5      , 1.5      , 2.5      , 1.5      , 2.5      ,\n",
      "       1.7515103, 1.5      ], dtype=float32)}\n"
     ]
    }
   ],
   "source": [
    "test_data = generate_case_3(200, corr, Beta, 2)\n",
    "X_test = test_data['X']\n",
    "g_true = test_data['g_X']\n",
    "dim_x = X_test.shape[0]\n",
    "print(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = ndm.normal(loc=0, scale=1, size=10) #parametric\n",
    "Z_2 = ndm.normal(loc=2, scale=1.5, size=10) #change point\n",
    "Z_3 = np.vstack((Z, Z*(Z_2>zeta)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr=0.5\n",
    "mean = np.zeros(5)\n",
    "cov = np.identity(5)*(1-corr) + np.ones((5, 5))*corr\n",
    "def multivariatet(mu,Sigma,N,M):\n",
    "        d = len(Sigma)\n",
    "        g = np.tile(np.random.gamma(N/2,1/2,M),(d,1)).T\n",
    "        Z = np.random.multivariate_normal(np.zeros(d),Sigma,M)\n",
    "        return mu + Z/np.sqrt(g/N)\n",
    "    \n",
    "X = multivariatet(mean,cov,5,5)\n",
    "X = np.clip(X, 0, 2) \n",
    "\n",
    "g_X = np.sqrt(X[:,0]*X[:,1])/5 + X[:,2]**2*X[:,3]/4 \\\n",
    "        + np.log(X[:,3]+1)/3 + np.exp(X[:,4])/2 - 1.91\\\n",
    "          +(0.2*(np.sqrt(X[:,0]*X[:,1])/5 + X[:,2]**2*X[:,3]/4 \\\n",
    "        + np.log(X[:,3]+1)/3 + np.exp(X[:,4])/2)**2 -0.45)*(Z_2>zeta)\n",
    "print(g_X)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gendata(n,zeta,r=5,corr=0.5):\n",
    "    Z_2 = ndm.normal(loc=2, scale=1.5, size=n) #change point\n",
    "    mean = np.zeros(r)\n",
    "    cov = np.identity(r)*(1-corr) + np.ones((r, r))*corr\n",
    "    def multivariatet(mu,Sigma,N,M):\n",
    "            d = len(Sigma)\n",
    "            g = np.tile(np.random.gamma(N/2,1/2,M),(d,1)).T\n",
    "            Z = np.random.multivariate_normal(np.zeros(d),Sigma,M)\n",
    "            return mu + Z/np.sqrt(g/N)\n",
    "    \n",
    "    X = multivariatet(mean,cov,r,n)\n",
    "    X = np.clip(X, 0, 2) \n",
    "\n",
    "    g_X = np.sqrt(X[:,0]*X[:,1])/5 + X[:,2]**2*X[:,3]/4 \\\n",
    "            + np.log(X[:,3]+1)/3 + np.exp(X[:,4])/2 - 1.91\\\n",
    "            +(0.2*(np.sqrt(X[:,0]*X[:,1])/5 + X[:,2]**2*X[:,3]/4 \\\n",
    "            + np.log(X[:,3]+1)/3 + np.exp(X[:,4])/2)**2 -1.36)*(Z_2>zeta)\n",
    "    return{'X': np.array(X, dtype='float32'),\n",
    "          'g_X': np.array(g_X, dtype='float32'),\n",
    "          'Z_2': np.array(Z_2, dtype = 'float32')\n",
    "          }\n",
    "\n",
    "print(gendata(5,zeta=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = gendata(1000,zeta=2)\n",
    "X_train = train_data['X']\n",
    "g_train = train_data['g_X']\n",
    "Z_2_train = train_data['Z_2']\n",
    "test_data = gendata(200, zeta=2)\n",
    "X_test = test_data['X']\n",
    "g_test = test_data['g_X']\n",
    "Z_2_test = test_data['Z_2']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "establish DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_layer = 3\n",
    "n_epoch = 50\n",
    "n_lr = 1e-3\n",
    "#X_train, X_test, g_train, g_test, Z_2_train,Z_2_test = \\\n",
    "    #train_test_split(X, g_X, Z_2, test_size=0.2,random_state=42)\n",
    "\n",
    "def g_DCP(train_data,X_test,Z_2_test,n_layer,n_node,n_lr,n_epoch):\n",
    "    #determine the location\n",
    "    \n",
    "    Z_2_tra = train_data['Z_2']\n",
    "    n1 = len(Z_2_tra)   #sample size of train data\n",
    "    n2 = len(Z_2_test)   #sample size of test data\n",
    "    locx_tra1 = np.where(Z_2_tra==1)  #Z_2>zeta in train data\n",
    "    locx_tra0 = np.where(Z_2_tra==0)\n",
    "    locx_tes1 = np.where(Z_2_test==1)  #Z_2>zeta in test data\n",
    "    locx_tes0 = np.where(Z_2_test==0)\n",
    "\n",
    "    #input data into torch.tensor\n",
    "    X_train = torch.Tensor(train_data['X'])\n",
    "    g_train_true = torch.Tensor(train_data['g_X'])\n",
    "    Z_2_train = torch.Tensor(train_data['Z_2'])\n",
    "    X_test = torch.Tensor(X_test)\n",
    "    Z_2_test = torch.Tensor(Z_2_test)\n",
    "    \n",
    "    #for I(Z_2>zeta)=0\n",
    "    X_train0 = X_train[locx_tra0]\n",
    "    g_train_true0 = g_train_true[locx_tra0]\n",
    "    Z_2_train0 = Z_2_train[locx_tra0]\n",
    "    X_test0 = X_test[locx_tra0]\n",
    "    Z_2_test0 = Z_2_test[locx_tra0]\n",
    "     #for I(Z_2>zeta)=1\n",
    "    X_train1 = X_train[locx_tra1]\n",
    "    g_train_true1 = g_train_true[locx_tra1]\n",
    "    Z_2_train1 = Z_2_train[locx_tra1]\n",
    "    X_test1 = X_test[locx_tra1]\n",
    "    Z_2_test1 = Z_2_test[locx_tra1]\n",
    "    class DNNModel(torch.nn.Module): #set the neural network\n",
    "        def __init__(self):\n",
    "            super(DNNModel, self).__init__()\n",
    "            layers = []\n",
    "            layers.append(nn.Linear(5, n_node)) #linear layer\n",
    "            layers.append(nn.ReLU()) #ReLU layer\n",
    "            for i in range(n_layer):\n",
    "                layers.append(nn.Linear(n_node, n_node))\n",
    "                layers.append(nn.ReLU())\n",
    "            layers.append(nn.Linear(n_node, 1))\n",
    "            self.model = nn.Sequential(*layers) #complete the neural network\n",
    "        def forward(self, x):   #forward propagation\n",
    "            y_pred = self.model(x)\n",
    "            return y_pred\n",
    "    model = DNNModel()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=n_lr)\n",
    "\n",
    "    for epoch in range(n_epoch):\n",
    "            pred_g_X = model(X_train)\n",
    "            loss = nn.MSELoss()  #can be defined as other loss\n",
    "            optimizer.zero_grad() #reset the gradient as 0\n",
    "            loss.backward()   #back propagation\n",
    "            optimizer.step()  #renew the parameter\n",
    "    \n",
    "    #\n",
    "    g_train0 = model(X_train0)\n",
    "    g_train1 = model(X_train1)\n",
    "    g_test0 = model(X_test0)\n",
    "    g_test1 = model(X_test1)\n",
    "    g_train = np.zeros(n1)\n",
    "    g_test = np.zeros(n2)\n",
    "    #return the two model to their location\n",
    "    g_train[locx_tra0] = g_train0\n",
    "    g_train[locx_tra1] = g_train1\n",
    "    g_test[locx_tes0] = g_test0\n",
    "    g_test[locx_tes1] = g_test1\n",
    "    g_train = g_train[:,0].detach().numpy()\n",
    "    g_test = g_test[:,0].detach().numpy()\n",
    "    return {\n",
    "        'g_train': g_train,\n",
    "        'g_test': g_test\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the location of specific item, using np.where for the array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zz = np.array([1,0,0,1,1,0,1])\n",
    "#zz = torch.Tensor(zz)\n",
    "#index = np.where(zz==1)\n",
    "#print(index)\n",
    "#zz = zz[index].detach().numpy()\n",
    "print(len(zz))\n",
    "print(zz[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa = np.array([1,1,4,5,1,4])\n",
    "b = []\n",
    "for a in aa:\n",
    "    b = np.append(b,a**2)\n",
    "print(np.array(aa))\n",
    "print(np.array(b))\n",
    "print(np.max(b))\n",
    "print(np.where(b==np.max(b)))\n",
    "print(np.zeros(5))\n",
    "ts = np.vstack((np.zeros(5),np.ones(5)))\n",
    "print(ts)\n",
    "p,n=ts.shape\n",
    "print(ts.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = ndm.binomial(1, 0.5, n) #parametric\n",
    "Z_2 = ndm.normal(loc=2, scale=1, size=n) #change point\n",
    "Z_2 = np.clip(Z_2, 1, 3)\n",
    "ZC = np.vstack((Z, Z*(Z_2>zeta)))\n",
    "print(ZC)\n",
    "Theta = [0,1]\n",
    "\n",
    "print(np.mean(np.exp(ZC.T@Theta+[1,0,3,0.5,0])))\n",
    "#data = generate_case_3(10,0.5,Theta = [0,1],zeta=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "#import matplotlib.pyplot as plt\n",
    "from data_generator import generate_case_3\n",
    "from g_deep import g_D\n",
    "from CCP_estimation import CCP_est\n",
    "#from iteration_dcp import Est_dcp\n",
    "from I_spline import I_S\n",
    "from Least_FD import LFD\n",
    "from g_dcp import g_DCP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tau = 10\n",
    "p = 3 \n",
    "n = 1000\n",
    "corr = 0.5 \n",
    "n_layer = 3\n",
    "n_node = 50\n",
    "n_epoch = 200 #\n",
    "Set_lr = np.array([2.8e-4, 3.2e-4, 4.2e-4]) #learning rate\n",
    "n_lr = 1e-4\n",
    "Theta = [0, 1]\n",
    "zeta = 2\n",
    "\n",
    "#dim_x = X_test.shape[0]\n",
    "u_value = np.array(np.linspace(0, tau, 50), dtype=\"float32\") \n",
    "Lambda_true = np.sqrt(u_value)/5 \n",
    "m = 10 \n",
    "nodevec = np.array(np.linspace(0, tau, m+2), dtype=\"float32\")\n",
    "\n",
    "m0 = 4 \n",
    "nodevec0 = np.array(np.linspace(0, 2, m0+2), dtype=\"float32\")\n",
    "\n",
    "node_D = np.array([35, 30, 30])   #deep\n",
    "lr_D = np.array([4e-4, 4e-4, 4e-4])\n",
    "\n",
    "c0 = np.array(0.1*np.ones(m+p), dtype=\"float32\") \n",
    "Theta0 = np.array([0,0], dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2769)\n",
      "1.9909074\n"
     ]
    }
   ],
   "source": [
    "\n",
    "u_value = np.array(np.linspace(0, tau, 50), dtype=\"float32\") \n",
    "Lambda_true = np.sqrt(u_value)/5 \n",
    "m = 10 \n",
    "nodevec = np.array(np.linspace(0, tau, m+2), dtype=\"float32\")\n",
    "\n",
    "m0 = 4 \n",
    "nodevec0 = np.array(np.linspace(0, 2, m0+2), dtype=\"float32\")\n",
    "\n",
    "node_D = np.array([35, 30, 30])   #deep\n",
    "lr_D = np.array([4e-4, 4e-4, 4e-4])\n",
    "\n",
    "c0 = np.array(0.1*np.ones(m+p), dtype=\"float32\") \n",
    "Theta0 = np.array([0,0], dtype='float32')\n",
    "\n",
    "\n",
    "train_data = generate_case_3(n, corr, Theta, zeta)\n",
    "Z_train = train_data['Z']\n",
    "U_train = train_data['U']\n",
    "De_train = train_data['De']\n",
    "g_train = train_data['g_X']\n",
    "Z_2_train = train_data['Z_2']\n",
    "\n",
    "zeta0 = np.mean(Z_2_train)\n",
    "\n",
    "test_data = generate_case_3(200, corr, Theta, zeta)\n",
    "X_test = test_data['X']\n",
    "g_true = test_data['g_X']\n",
    "Z_2_test = test_data['Z_2']\n",
    "\n",
    "\n",
    "Z_t = torch.Tensor(Z_train)\n",
    "Z_2_t = torch.Tensor(Z_2_train)\n",
    "g_X_t = torch.Tensor(g_train)\n",
    "De_t = torch.Tensor(De_train)\n",
    "ZC_t = np.vstack((Z_train,Z_train*(Z_2_train>zeta0)))\n",
    "ZC_t = torch.Tensor(ZC_t)\n",
    "Theta = torch.Tensor(Theta)\n",
    "Lambda_U = I_S(m,c0,U_train,nodevec)\n",
    "Lambda_U_t = I_S(m,c0,U_train,nodevec)\n",
    "Lambda_U_t = torch.Tensor(Lambda_U_t)\n",
    "Lam1 = Lambda_U_t * torch.exp(ZC_t.T@Theta + g_X_t)\n",
    "loss_fun = -torch.mean(De_t*torch.log(1-torch.exp(-Lam1)+1e-5) - (1-De_t)*Lam1)\n",
    "print(loss_fun)\n",
    "print(zeta0)\n",
    "from g_deep import g_D\n",
    "from CCP_estimation import CCP_est\n",
    "from iteration_dcp import Est_dcp\n",
    "from I_spline import I_S\n",
    "from Least_FD import LFD\n",
    "from g_dcp import g_DCP\n",
    "from Theta_estimate import Theta_est\n",
    "from zeta_estimate import zeta_est\n",
    "\n",
    "\n",
    "\n",
    "#g_X = g_DCP(train_data,X_test,Z_2_test,Lambda_U_t,Theta,Theta0,zeta,n_layer,n_node,n_lr,n_epoch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\txw\\AppData\\Local\\Temp\\ipykernel_31892\\2321191037.py:22: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ..\\torch\\csrc\\utils\\tensor_new.cpp:277.)\n",
      "  X_train0 = torch.Tensor(X_train[locx_tra0,:])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "Z_2_tra = train_data['Z_2']\n",
    "n1 = len(Z_2_tra)   #sample size of train data\n",
    "n2 = len(Z_2_test)   #sample size of test data\n",
    "locx_tra1 = np.where(Z_2_tra>zeta0)  #Z_2>zeta in train data\n",
    "locx_tra0 = np.where(Z_2_tra<=zeta0)\n",
    "locx_tes1 = np.where(Z_2_test>zeta0)  #Z_2>zeta in test data\n",
    "locx_tes0 = np.where(Z_2_test<=zeta0)\n",
    "\n",
    "Z_train = torch.Tensor(train_data['Z'])\n",
    "X_train = torch.Tensor(train_data['X'])\n",
    "U_train = torch.Tensor(train_data['U'])\n",
    "De_train = torch.Tensor(train_data['De'])\n",
    "g_train_true = torch.Tensor(train_data['g_X'])\n",
    "Z_2_train = torch.Tensor(train_data['Z_2'])\n",
    "Lambda_U0 = Lambda_U[locx_tra0]\n",
    "Lambda_U1 = Lambda_U[locx_tra1]\n",
    "X_test0 = X_test[locx_tes0]\n",
    "X_test1 = X_test[locx_tes1]\n",
    "\n",
    "#input data into torch.tensor\n",
    "Z_train0 = torch.Tensor(Z_train[locx_tra0])\n",
    "X_train0 = torch.Tensor(X_train[locx_tra0,:])\n",
    "U_train0 = torch.Tensor(U_train[locx_tra0])\n",
    "De_train0 = torch.Tensor(De_train[locx_tra0])\n",
    "g_train_true0 = torch.Tensor(g_train_true[locx_tra0])\n",
    "Z_2_train0 = torch.Tensor(Z_2_train[locx_tra0])\n",
    "Lambda_U0 = torch.Tensor(Lambda_U0)\n",
    "X_test0 = torch.Tensor(X_test0)\n",
    "\n",
    "Z_train1 = torch.Tensor(Z_train[locx_tra1])\n",
    "X_train1 = torch.Tensor(X_train[locx_tra1,:])\n",
    "U_train1 = torch.Tensor(U_train[locx_tra1])\n",
    "De_train1 = torch.Tensor(De_train[locx_tra1])\n",
    "g_train_true1 = torch.Tensor(g_train_true[locx_tra1])\n",
    "Z_2_train1 = torch.Tensor(Z_2_train[locx_tra1])\n",
    "Lambda_U1 = torch.Tensor(Lambda_U1)   \n",
    "X_test1 = torch.Tensor(X_test1)\n",
    "#print('aasq')\n",
    "\n",
    "\n",
    "Theta0 = torch.Tensor(Theta0)\n",
    "#print(locx_tra1)\n",
    "#print(Z_2_train[locx_tra1])\n",
    "#print(X_train[locx_tra1,:])\n",
    "#print(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.06659405 0.06851879 0.07605243 0.06420349 0.06659405 0.07370904\n",
      " 0.07478966 0.08151164 0.07544191 0.06514858 0.0653682  0.06913154\n",
      " 0.06659405 0.06181982 0.06894178 0.07401966 0.07229486 0.06894496\n",
      " 0.07214272 0.07086523 0.06477824 0.06659405 0.07485047 0.06930139\n",
      " 0.07056303 0.07275105 0.07536077 0.06898375 0.07572173 0.06959607\n",
      " 0.06434268 0.06898209 0.06624186 0.06773318 0.07598473 0.07104519\n",
      " 0.07309871 0.06691195 0.06910893 0.076205   0.06982376 0.07638603\n",
      " 0.06655115 0.07901655 0.06830037 0.07093181 0.06650609 0.06605513\n",
      " 0.06397839 0.06718388 0.07698496 0.06727683 0.06659405 0.06659405\n",
      " 0.08010241 0.06835021 0.07592168 0.06480147 0.0663399  0.0664574\n",
      " 0.06659405 0.06659405 0.06659405 0.06756331 0.07763471 0.06932912\n",
      " 0.07228421 0.07725938 0.06659405 0.06659405 0.06603593 0.06439888\n",
      " 0.0750322  0.0762057  0.07558505 0.06840745 0.06760281 0.07808123\n",
      " 0.06669836 0.06425573 0.06549397 0.07536077 0.06927495 0.06659405\n",
      " 0.06659405 0.06434268 0.0684566  0.07556543 0.06714419 0.06601067\n",
      " 0.06566693 0.07260539 0.0759185  0.07737553 0.07660986 0.07416914\n",
      " 0.07276188 0.06883907]\n"
     ]
    }
   ],
   "source": [
    "#train DNN for Z_2<=zeta\n",
    "class DNNModel0(torch.nn.Module): #set the neural network\n",
    "    def __init__(self):\n",
    "        super(DNNModel0, self).__init__()\n",
    "        layers = []\n",
    "        layers.append(nn.Linear(5, n_node)) #linear layer\n",
    "        layers.append(nn.ReLU()) #ReLU layer\n",
    "        for i in range(n_layer):\n",
    "            layers.append(nn.Linear(n_node, n_node))\n",
    "            layers.append(nn.ReLU())\n",
    "        layers.append(nn.Linear(n_node, 1))\n",
    "        self.model = nn.Sequential(*layers) #complete the neural network\n",
    "    def forward(self, x):   #forward propagation\n",
    "        y_pred = self.model(x)\n",
    "        return y_pred\n",
    "\n",
    "model = DNNModel0()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=n_lr)\n",
    "\n",
    "\n",
    "def my_loss(De, Z, Theta, Lambda_U, g_X, Z_2, zeta):\n",
    "    ZC = np.vstack((Z,Z*(Z_2>zeta)))\n",
    "    ZC = torch.Tensor(ZC)\n",
    "    Lam1 = Lambda_U * torch.exp(ZC.T@Theta + g_X)\n",
    "    loss_fun = -torch.mean(De*torch.log(1-torch.exp(-Lam1)+1e-5) - (1-De)*Lam1)\n",
    "    return loss_fun\n",
    "\n",
    "for epoch in range(n_epoch):\n",
    "    pred_g_X = model(X_train0)\n",
    "    loss = my_loss(De_train0, Z_train0, Theta0, Lambda_U0, Z_2_train0, zeta0, pred_g_X[:, 0])\n",
    "    loss.requires_grad_(True)\n",
    "    optimizer.zero_grad() #reset the gradient as 0\n",
    "    loss.backward()   #back propagation\n",
    "    optimizer.step()  #renew the parameter\n",
    "\n",
    "g_train0 = model(X_train0)\n",
    "g_test0 = model(X_test0)\n",
    "g_train0 = g_train0[:,0].detach().numpy()\n",
    "g_test0 = g_test0[:,0].detach().numpy()\n",
    "print(g_test0)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.12591355 0.12669073 0.1341394  0.1306205  0.11722872 0.12826374\n",
      " 0.12627444 0.12880734 0.10906009 0.12428268 0.13195208 0.13202804\n",
      " 0.12963593 0.12428268 0.1223175  0.13131829 0.15154886 0.12428269\n",
      " 0.12524717 0.1488354  0.13270967 0.12817612 0.11344585 0.13578539\n",
      " 0.12045701 0.12488264 0.12428269 0.12428268 0.12409344 0.12406356\n",
      " 0.13737212 0.12242812 0.11956942 0.12726966 0.1290403  0.12497766\n",
      " 0.12579325 0.12428268 0.13346875 0.1292221  0.12889557 0.12710352\n",
      " 0.14211786 0.13345212 0.13028112 0.12157978 0.14624862 0.13011797\n",
      " 0.1488354  0.13068174 0.13339972 0.12893032 0.12096152 0.12428269\n",
      " 0.13340841 0.12436281 0.12461098 0.12190942 0.12621816 0.10953461\n",
      " 0.12428269 0.12525703 0.13499019 0.11834127 0.12428268 0.12612283\n",
      " 0.12420039 0.12892649 0.11732037 0.11107737 0.1340236  0.12428269\n",
      " 0.12477808 0.13041481 0.13501124 0.12814245 0.12199256 0.12500899\n",
      " 0.13738795 0.11408579 0.12779143 0.12655959 0.12428268 0.11189784\n",
      " 0.12490163 0.12767398 0.13815051 0.12428269 0.11270965 0.12593651\n",
      " 0.12428268 0.12375093 0.12325659 0.12499452 0.12863044 0.12419258\n",
      " 0.11732038 0.12657343 0.1288724  0.12830815 0.12721969 0.12967333]\n",
      "[0.12591355 0.06659405 0.12669073 0.06851879 0.1341394  0.13062049\n",
      " 0.11722872 0.07605243 0.06420349 0.12826374 0.06659405 0.07370904\n",
      " 0.12627444 0.12880734 0.07478966 0.10906009 0.12428268 0.08151164\n",
      " 0.07544191 0.13195208 0.13202804 0.12963593 0.06514858 0.0653682\n",
      " 0.12428268 0.06913154 0.06659405 0.1223175  0.06181982 0.13131829\n",
      " 0.06894178 0.07401966 0.07229486 0.15154886 0.12428269 0.12524717\n",
      " 0.14883541 0.13270967 0.12817612 0.11344585 0.13578539 0.12045701\n",
      " 0.12488264 0.06894496 0.12428269 0.07214272 0.12428268 0.07086523\n",
      " 0.12409344 0.12406356 0.06477824 0.13737212 0.12242812 0.06659405\n",
      " 0.07485047 0.06930139 0.11956942 0.07056303 0.12726966 0.1290403\n",
      " 0.12497766 0.12579325 0.12428268 0.07275105 0.13346875 0.1292221\n",
      " 0.07536077 0.06898375 0.12889557 0.07572173 0.06959607 0.06434268\n",
      " 0.12710352 0.06898209 0.14211786 0.06624186 0.06773318 0.13345212\n",
      " 0.07598473 0.07104519 0.13028112 0.07309871 0.12157978 0.14624862\n",
      " 0.13011797 0.14883541 0.06691195 0.13068174 0.06910893 0.13339972\n",
      " 0.12893032 0.076205   0.06982376 0.12096152 0.12428269 0.07638603\n",
      " 0.06655115 0.13340841 0.12436281 0.12461098 0.12190942 0.12621816\n",
      " 0.07901655 0.10953461 0.06830037 0.12428269 0.12525703 0.13499019\n",
      " 0.07093181 0.06650609 0.11834127 0.06605513 0.06397839 0.12428268\n",
      " 0.06718388 0.07698496 0.06727683 0.06659405 0.06659405 0.08010241\n",
      " 0.12612283 0.06835021 0.07592168 0.06480147 0.12420039 0.0663399\n",
      " 0.0664574  0.12892649 0.11732037 0.11107737 0.13402361 0.06659405\n",
      " 0.12428269 0.12477808 0.13041481 0.13501124 0.12814245 0.12199256\n",
      " 0.12500899 0.06659405 0.06659405 0.06756331 0.07763471 0.13738795\n",
      " 0.06932912 0.11408579 0.07228421 0.07725938 0.06659405 0.12779143\n",
      " 0.06659405 0.12655959 0.12428268 0.11189784 0.06603593 0.06439888\n",
      " 0.12490163 0.0750322  0.12767398 0.13815051 0.0762057  0.07558505\n",
      " 0.12428269 0.06840745 0.06760281 0.07808123 0.06669836 0.11270965\n",
      " 0.12593651 0.06425573 0.12428268 0.12375093 0.06549397 0.07536077\n",
      " 0.06927495 0.12325659 0.06659405 0.06659405 0.12499452 0.06434268\n",
      " 0.0684566  0.07556543 0.12863044 0.12419258 0.11732038 0.12657343\n",
      " 0.06714419 0.12887239 0.06601067 0.06566693 0.12830815 0.07260539\n",
      " 0.0759185  0.07737553 0.07660986 0.07416914 0.07276188 0.12721969\n",
      " 0.06883907 0.12967333]\n"
     ]
    }
   ],
   "source": [
    "#train DNN for Z_2>zeta\n",
    "class DNNModel1(torch.nn.Module): #set the neural network\n",
    "    def __init__(self):\n",
    "        super(DNNModel1, self).__init__()\n",
    "        layers = []\n",
    "        layers.append(nn.Linear(5, n_node)) #linear layer\n",
    "        layers.append(nn.ReLU()) #ReLU layer\n",
    "        for i in range(n_layer):\n",
    "            layers.append(nn.Linear(n_node, n_node))\n",
    "            layers.append(nn.ReLU())\n",
    "        layers.append(nn.Linear(n_node, 1))\n",
    "        self.model = nn.Sequential(*layers) #complete the neural network\n",
    "    def forward(self, x):   #forward propagation\n",
    "        y_pred = self.model(x)\n",
    "        return y_pred\n",
    "\n",
    "model = DNNModel1()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=n_lr)\n",
    "\n",
    "\n",
    "    #def my_loss(De, Z, Theta, Lambda_U, g_X, Z_2, zeta):\n",
    "        #ZC = np.vstack((Z,Z*(Z_2>zeta)))\n",
    "        #Lam1 = Lambda_U * torch.exp(ZC.T@Theta + g_X)\n",
    "        #loss_fun = -torch.mean(De*torch.log(1-torch.exp(-Lam1)+1e-5) - (1-De)*Lam1)\n",
    "        #return loss_fun\n",
    "\n",
    "for epoch in range(n_epoch):\n",
    "    pred_g_X = model(X_train1)\n",
    "    loss = my_loss(De_train1, Z_train1, Theta0, Lambda_U1, Z_2_train1, zeta0, pred_g_X[:, 0])\n",
    "    loss.requires_grad_(True)\n",
    "    optimizer.zero_grad() #reset the gradient as 0\n",
    "    loss.backward()   #back propagation\n",
    "    optimizer.step()  #renew the parameter\n",
    "\n",
    "g_train1 = model(X_train1)\n",
    "g_test1 = model(X_test1)\n",
    "g_train1 = g_train1[:,0].detach().numpy()\n",
    "g_test1 = g_test1[:,0].detach().numpy()\n",
    "    \n",
    "\n",
    "#reorganize the data\n",
    "g_train = np.array(np.zeros(n1))\n",
    "g_train[locx_tra0] = g_train0\n",
    "g_train[locx_tra1] = g_train1\n",
    "\n",
    "g_test = np.array(np.zeros(n2))\n",
    "g_test[locx_tes0] = g_test0\n",
    "g_test[locx_tes1] = g_test1\n",
    "\n",
    "print(g_test1)\n",
    "\n",
    "print(g_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq=0.05\n",
    "Z_min = np.min(Z_2)\n",
    "Z_max = np.max(Z_2)\n",
    "num = np.floor((Z_max-Z_min)/seq)\n",
    "zeta_grid = np.linspace(Z_min, Z_max, num)  #the search grid\n",
    "\n",
    "#define the log-likelihood loss\n",
    "def BZ2(*args):\n",
    "    ZC = np.vstack((Z,Z*(Z_2>args[0])))\n",
    "    Lam = Lambda_U * np.exp(ZC.T @ Theta + g_X)\n",
    "    Loss_F = np.mean(-De * np.log(1 - np.exp(-Lam) + 1e-5) + (1 - De) * Lam)\n",
    "    return Loss_F\n",
    "    \n",
    "zeta_loss = np.array([])\n",
    "for zeta in zeta_grid:\n",
    "    zeta_loss = np.append(zeta_loss, BZ2(zeta))\n",
    "loss_min = np.min(zeta_loss)\n",
    "loc = np.where(zeta_loss==loss_min)\n",
    "zeta_est = zeta_grid[loc]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cpdnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
